{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c4896b-27ce-43fb-82a9-105c0aaa7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, KBinsDiscretizer\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# hide Warning(s)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' #last_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8672b5-5540-4c30-8a87-488bccf58507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(project, path='./dataset/'):\n",
    "    data = pd.read_csv(path+project+'_data.tsv', sep='\\t', index_col=0)\n",
    "    pairs = pd.read_csv(path+project+'_pairs.tsv', sep='\\t', index_col=0)\n",
    "    train = pd.read_csv(path+project+'_train.tsv', sep='\\t', index_col=0)\n",
    "    valid = pd.read_csv(path+project+'_valid.tsv', sep='\\t', index_col=0)\n",
    "    test = pd.read_csv(path+project+'_test.tsv', sep='\\t', index_col=0)\n",
    "    pairTrain = pd.read_csv(path+project+'_pairTrain.tsv', sep='\\t', index_col=0)\n",
    "    train_pairs = pd.read_csv(path+project+'_train_pairs.tsv', sep='\\t', index_col=0)\n",
    "    pairValid = pd.read_csv(path+project+'_pairValid.tsv', sep='\\t', index_col=0)\n",
    "    valid_pairs = pd.read_csv(path+project+'_valid_pairs.tsv', sep='\\t', index_col=0)\n",
    "    featues = pd.read_csv(path+project+'_features.tsv', sep='\\t', index_col=0)\n",
    "    return data, pairs, train, valid, test, pairTrain, train_pairs, pairValid, valid_pairs, featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f3d11b6-e594-481f-a091-77e503893fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBD = ['27', '36', '38', '48_1', '59']\n",
    "CRC = ['18_2', '26', '28_2', '81_2', '82', '83', '87', '91', '93_3', '97', '99_2']\n",
    "#clf = LogisticRegression(random_state=0)\n",
    "#clf = Pipeline([('scaler', KBinsDiscretizer(encode='ordinal')), ('logist', LogisticRegression(random_state=0))])\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_features=0.2)\n",
    "clf = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier(n_estimators=100, max_features=0.2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc6944f5-5633-4fa2-82fd-84afe1e739c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = '38'\n",
    "data, pairs, train, valid, test, pairTrain, train_pairs, pairValid, valid_pairs, features = load_data(project, path='./dataset/')\n",
    "\n",
    "extend_datasets = {}\n",
    "for i in IBD:\n",
    "    if i!=project:\n",
    "        extend_datasets[i] = load_data(i, path='./dataset/')[0]\n",
    "extend_datasets[project+'_train'] = train\n",
    "extend_datasets[project+'_valid'] = valid\n",
    "extend_datasets[project+'_test'] = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21036e4b-728e-4447-8653-c694c24c758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(data, features, pairs, ntree=100, nsample=7, min_paired=0.5):\n",
    "    trees = []\n",
    "    for i in range(ntree):\n",
    "        clf = DecisionTreeClassifier(random_state=i, max_features=0.25)\n",
    "        if random.random()>min_paired:\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=nsample, random_state=i)\n",
    "            for _, (_, index) in enumerate(sss.split(data.iloc[:, :-1], data.iloc[:, -1])): pass\n",
    "            subdata = data.iloc[index, :]\n",
    "            clf.fit(subdata[features], subdata['Group'])\n",
    "            trees.append(clf)\n",
    "        else:\n",
    "            rindex = random.sample(list(pairs.index), int(nsample/2)+1)\n",
    "            rsamples = list(set(pairs.loc[rindex, 'Case']).union(set(pairs.loc[rindex, 'Control'])))\n",
    "            subdata = data.iloc[rsamples, :]\n",
    "            clf.fit(subdata[features], subdata['Group'])\n",
    "            trees.append(clf)\n",
    "    return trees\n",
    "\n",
    "def predict_step(trees, data, features):\n",
    "    result = []\n",
    "    for model in trees:\n",
    "        res = model.predict(data[features])\n",
    "        result.append(res)\n",
    "    #print(result)\n",
    "    return np.round(np.array(result).mean(0), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d54c3d-bdb8-45ba-864f-86b5b34ddbc7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### IBD 27 101 3 0.0\n",
      "### IBD 27 101 3 0.1\n",
      "### IBD 27 101 3 0.2\n",
      "### IBD 27 101 3 0.3\n",
      "### IBD 27 101 3 0.4\n",
      "### IBD 27 101 3 0.5\n",
      "### IBD 27 101 3 0.6\n",
      "### IBD 27 101 3 0.7\n",
      "### IBD 27 101 3 0.8\n",
      "### IBD 27 101 3 0.9\n",
      "### IBD 27 101 3 1.0\n",
      "### IBD 27 101 5 0.0\n",
      "### IBD 27 101 5 0.1\n",
      "### IBD 27 101 5 0.2\n",
      "### IBD 27 101 5 0.3\n",
      "### IBD 27 101 5 0.4\n",
      "### IBD 27 101 5 0.5\n",
      "### IBD 27 101 5 0.6\n",
      "### IBD 27 101 5 0.7\n",
      "### IBD 27 101 5 0.8\n",
      "### IBD 27 101 5 0.9\n",
      "### IBD 27 101 5 1.0\n",
      "### IBD 27 101 7 0.0\n",
      "### IBD 27 101 7 0.1\n",
      "### IBD 27 101 7 0.2\n",
      "### IBD 27 101 7 0.3\n",
      "### IBD 27 101 7 0.4\n",
      "### IBD 27 101 7 0.5\n",
      "### IBD 27 101 7 0.6\n",
      "### IBD 27 101 7 0.7\n",
      "### IBD 27 101 7 0.8\n",
      "### IBD 27 101 7 0.9\n",
      "### IBD 27 101 7 1.0\n",
      "### IBD 27 101 9 0.0\n",
      "### IBD 27 101 9 0.1\n",
      "### IBD 27 101 9 0.2\n",
      "### IBD 27 101 9 0.3\n",
      "### IBD 27 101 9 0.4\n",
      "### IBD 27 101 9 0.5\n",
      "### IBD 27 101 9 0.6\n",
      "### IBD 27 101 9 0.7\n",
      "### IBD 27 101 9 0.8\n",
      "### IBD 27 101 9 0.9\n",
      "### IBD 27 101 9 1.0\n",
      "### IBD 27 101 11 0.0\n",
      "### IBD 27 101 11 0.1\n",
      "### IBD 27 101 11 0.2\n",
      "### IBD 27 101 11 0.3\n",
      "### IBD 27 101 11 0.4\n",
      "### IBD 27 101 11 0.5\n",
      "### IBD 27 101 11 0.6\n",
      "### IBD 27 101 11 0.7\n",
      "### IBD 27 101 11 0.8\n",
      "### IBD 27 101 11 0.9\n",
      "### IBD 27 101 11 1.0\n",
      "### IBD 36 101 3 0.0\n",
      "### IBD 36 101 3 0.1\n",
      "### IBD 36 101 3 0.2\n",
      "### IBD 36 101 3 0.3\n",
      "### IBD 36 101 3 0.4\n",
      "### IBD 36 101 3 0.5\n",
      "### IBD 36 101 3 0.6\n",
      "### IBD 36 101 3 0.7\n",
      "### IBD 36 101 3 0.8\n",
      "### IBD 36 101 3 0.9\n",
      "### IBD 36 101 3 1.0\n",
      "### IBD 36 101 5 0.0\n",
      "### IBD 36 101 5 0.1\n",
      "### IBD 36 101 5 0.2\n",
      "### IBD 36 101 5 0.3\n",
      "### IBD 36 101 5 0.4\n",
      "### IBD 36 101 5 0.5\n",
      "### IBD 36 101 5 0.6\n",
      "### IBD 36 101 5 0.7\n",
      "### IBD 36 101 5 0.8\n",
      "### IBD 36 101 5 0.9\n",
      "### IBD 36 101 5 1.0\n",
      "### IBD 36 101 7 0.0\n",
      "### IBD 36 101 7 0.1\n",
      "### IBD 36 101 7 0.2\n",
      "### IBD 36 101 7 0.3\n",
      "### IBD 36 101 7 0.4\n",
      "### IBD 36 101 7 0.5\n",
      "### IBD 36 101 7 0.6\n",
      "### IBD 36 101 7 0.7\n",
      "### IBD 36 101 7 0.8\n",
      "### IBD 36 101 7 0.9\n",
      "### IBD 36 101 7 1.0\n",
      "### IBD 36 101 9 0.0\n",
      "### IBD 36 101 9 0.1\n",
      "### IBD 36 101 9 0.2\n",
      "### IBD 36 101 9 0.3\n",
      "### IBD 36 101 9 0.4\n",
      "### IBD 36 101 9 0.5\n",
      "### IBD 36 101 9 0.6\n",
      "### IBD 36 101 9 0.7\n",
      "### IBD 36 101 9 0.8\n",
      "### IBD 36 101 9 0.9\n",
      "### IBD 36 101 9 1.0\n",
      "### IBD 36 101 11 0.0\n",
      "### IBD 36 101 11 0.1\n",
      "### IBD 36 101 11 0.2\n",
      "### IBD 36 101 11 0.3\n",
      "### IBD 36 101 11 0.4\n",
      "### IBD 36 101 11 0.5\n",
      "### IBD 36 101 11 0.6\n",
      "### IBD 36 101 11 0.7\n",
      "### IBD 36 101 11 0.8\n",
      "### IBD 36 101 11 0.9\n",
      "### IBD 36 101 11 1.0\n",
      "### IBD 38 101 3 0.0\n",
      "### IBD 38 101 3 0.1\n",
      "### IBD 38 101 3 0.2\n",
      "### IBD 38 101 3 0.3\n",
      "### IBD 38 101 3 0.4\n",
      "### IBD 38 101 3 0.5\n",
      "### IBD 38 101 3 0.6\n",
      "### IBD 38 101 3 0.7\n",
      "### IBD 38 101 3 0.8\n",
      "### IBD 38 101 3 0.9\n",
      "### IBD 38 101 3 1.0\n",
      "### IBD 38 101 5 0.0\n",
      "### IBD 38 101 5 0.1\n",
      "### IBD 38 101 5 0.2\n",
      "### IBD 38 101 5 0.3\n",
      "### IBD 38 101 5 0.4\n",
      "### IBD 38 101 5 0.5\n",
      "### IBD 38 101 5 0.6\n",
      "### IBD 38 101 5 0.7\n",
      "### IBD 38 101 5 0.8\n",
      "### IBD 38 101 5 0.9\n",
      "### IBD 38 101 5 1.0\n",
      "### IBD 38 101 7 0.0\n",
      "### IBD 38 101 7 0.1\n",
      "### IBD 38 101 7 0.2\n",
      "### IBD 38 101 7 0.3\n",
      "### IBD 38 101 7 0.4\n",
      "### IBD 38 101 7 0.5\n",
      "### IBD 38 101 7 0.6\n",
      "### IBD 38 101 7 0.7\n",
      "### IBD 38 101 7 0.8\n",
      "### IBD 38 101 7 0.9\n",
      "### IBD 38 101 7 1.0\n",
      "### IBD 38 101 9 0.0\n",
      "### IBD 38 101 9 0.1\n",
      "### IBD 38 101 9 0.2\n",
      "### IBD 38 101 9 0.3\n",
      "### IBD 38 101 9 0.4\n",
      "### IBD 38 101 9 0.5\n",
      "### IBD 38 101 9 0.6\n",
      "### IBD 38 101 9 0.7\n",
      "### IBD 38 101 9 0.8\n",
      "### IBD 38 101 9 0.9\n",
      "### IBD 38 101 9 1.0\n",
      "### IBD 38 101 11 0.0\n",
      "### IBD 38 101 11 0.1\n",
      "### IBD 38 101 11 0.2\n",
      "### IBD 38 101 11 0.3\n",
      "### IBD 38 101 11 0.4\n",
      "### IBD 38 101 11 0.5\n",
      "### IBD 38 101 11 0.6\n",
      "### IBD 38 101 11 0.7\n",
      "### IBD 38 101 11 0.8\n",
      "### IBD 38 101 11 0.9\n",
      "### IBD 38 101 11 1.0\n",
      "### IBD 48_1 101 3 0.0\n",
      "### IBD 48_1 101 3 0.1\n",
      "### IBD 48_1 101 3 0.2\n",
      "### IBD 48_1 101 3 0.3\n",
      "### IBD 48_1 101 3 0.4\n",
      "### IBD 48_1 101 3 0.5\n",
      "### IBD 48_1 101 3 0.6\n",
      "### IBD 48_1 101 3 0.7\n",
      "### IBD 48_1 101 3 0.8\n",
      "### IBD 48_1 101 3 0.9\n",
      "### IBD 48_1 101 3 1.0\n",
      "### IBD 48_1 101 5 0.0\n",
      "### IBD 48_1 101 5 0.1\n",
      "### IBD 48_1 101 5 0.2\n",
      "### IBD 48_1 101 5 0.3\n",
      "### IBD 48_1 101 5 0.4\n",
      "### IBD 48_1 101 5 0.5\n",
      "### IBD 48_1 101 5 0.6\n",
      "### IBD 48_1 101 5 0.7\n",
      "### IBD 48_1 101 5 0.8\n",
      "### IBD 48_1 101 5 0.9\n",
      "### IBD 48_1 101 5 1.0\n",
      "### IBD 48_1 101 7 0.0\n",
      "### IBD 48_1 101 7 0.1\n",
      "### IBD 48_1 101 7 0.2\n",
      "### IBD 48_1 101 7 0.3\n",
      "### IBD 48_1 101 7 0.4\n",
      "### IBD 48_1 101 7 0.5\n",
      "### IBD 48_1 101 7 0.6\n",
      "### IBD 48_1 101 7 0.7\n",
      "### IBD 48_1 101 7 0.8\n",
      "### IBD 48_1 101 7 0.9\n",
      "### IBD 48_1 101 7 1.0\n",
      "### IBD 48_1 101 9 0.0\n",
      "### IBD 48_1 101 9 0.1\n",
      "### IBD 48_1 101 9 0.2\n",
      "### IBD 48_1 101 9 0.3\n",
      "### IBD 48_1 101 9 0.4\n",
      "### IBD 48_1 101 9 0.5\n",
      "### IBD 48_1 101 9 0.6\n",
      "### IBD 48_1 101 9 0.7\n",
      "### IBD 48_1 101 9 0.8\n",
      "### IBD 48_1 101 9 0.9\n",
      "### IBD 48_1 101 9 1.0\n",
      "### IBD 48_1 101 11 0.0\n",
      "### IBD 48_1 101 11 0.1\n",
      "### IBD 48_1 101 11 0.2\n",
      "### IBD 48_1 101 11 0.3\n",
      "### IBD 48_1 101 11 0.4\n",
      "### IBD 48_1 101 11 0.5\n",
      "### IBD 48_1 101 11 0.6\n",
      "### IBD 48_1 101 11 0.7\n",
      "### IBD 48_1 101 11 0.8\n",
      "### IBD 48_1 101 11 0.9\n",
      "### IBD 48_1 101 11 1.0\n",
      "### IBD 59 101 3 0.0\n",
      "### IBD 59 101 3 0.1\n",
      "### IBD 59 101 3 0.2\n",
      "### IBD 59 101 3 0.3\n",
      "### IBD 59 101 3 0.4\n",
      "### IBD 59 101 3 0.5\n",
      "### IBD 59 101 3 0.6\n",
      "### IBD 59 101 3 0.7\n",
      "### IBD 59 101 3 0.8\n",
      "### IBD 59 101 3 0.9\n",
      "### IBD 59 101 3 1.0\n",
      "### IBD 59 101 5 0.0\n",
      "### IBD 59 101 5 0.1\n",
      "### IBD 59 101 5 0.2\n",
      "### IBD 59 101 5 0.3\n",
      "### IBD 59 101 5 0.4\n",
      "### IBD 59 101 5 0.5\n",
      "### IBD 59 101 5 0.6\n",
      "### IBD 59 101 5 0.7\n",
      "### IBD 59 101 5 0.8\n",
      "### IBD 59 101 5 0.9\n",
      "### IBD 59 101 5 1.0\n",
      "### IBD 59 101 7 0.0\n",
      "### IBD 59 101 7 0.1\n",
      "### IBD 59 101 7 0.2\n",
      "### IBD 59 101 7 0.3\n",
      "### IBD 59 101 7 0.4\n",
      "### IBD 59 101 7 0.5\n",
      "### IBD 59 101 7 0.6\n",
      "### IBD 59 101 7 0.7\n",
      "### IBD 59 101 7 0.8\n",
      "### IBD 59 101 7 0.9\n",
      "### IBD 59 101 7 1.0\n",
      "### IBD 59 101 9 0.0\n",
      "### IBD 59 101 9 0.1\n",
      "### IBD 59 101 9 0.2\n",
      "### IBD 59 101 9 0.3\n",
      "### IBD 59 101 9 0.4\n",
      "### IBD 59 101 9 0.5\n",
      "### IBD 59 101 9 0.6\n",
      "### IBD 59 101 9 0.7\n",
      "### IBD 59 101 9 0.8\n",
      "### IBD 59 101 9 0.9\n",
      "### IBD 59 101 9 1.0\n",
      "### IBD 59 101 11 0.0\n",
      "### IBD 59 101 11 0.1\n",
      "### IBD 59 101 11 0.2\n",
      "### IBD 59 101 11 0.3\n",
      "### IBD 59 101 11 0.4\n",
      "### IBD 59 101 11 0.5\n",
      "### IBD 59 101 11 0.6\n",
      "### IBD 59 101 11 0.7\n",
      "### IBD 59 101 11 0.8\n",
      "### IBD 59 101 11 0.9\n",
      "### IBD 59 101 11 1.0\n"
     ]
    }
   ],
   "source": [
    "projects = ['27', '36', '38', '48_1', '59']\n",
    "disease = 'IBD'\n",
    "ntree = 101\n",
    "nsamples = [3, 5, 7, 9, 11]\n",
    "min_paireds = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "results = []\n",
    "for project in projects:\n",
    "    ### data\n",
    "    data, pairs, train, valid, test, pairTrain, train_pairs, pairValid, valid_pairs, features = load_data(project, path='./dataset/')\n",
    "    extend_datasets = {}\n",
    "    LODO_data = pd.DataFrame()\n",
    "    LODO_pairs = pd.DataFrame()\n",
    "    for i in projects:\n",
    "        if i!=project:\n",
    "            extend_datasets[i], extend_pairs = load_data(i, path='./dataset/')[:2]\n",
    "            temp = extend_datasets[i].copy()\n",
    "            temp.index = i+'_'+temp.index\n",
    "            LODO_data = pd.concat([LODO_data, temp], axis=0, sort=False)\n",
    "            extend_pairs = i+'_'+extend_pairs\n",
    "            LODO_pairs = pd.concat([LODO_pairs, extend_pairs], axis=0, sort=False)\n",
    "    extend_datasets[project+'_train'] = train\n",
    "    extend_datasets[project+'_valid'] = valid\n",
    "    extend_datasets[project+'_test'] = test\n",
    "\n",
    "    #LODO_data.shape\n",
    "    LODO_pairs_index = []\n",
    "    samples = list(LODO_data.index)\n",
    "    for case, control in LODO_pairs.values:\n",
    "        LODO_pairs_index.append([samples.index(case), samples.index(control)])\n",
    "    LODO_pairs_index = pd.DataFrame(LODO_pairs_index, columns=['Case', 'Control'])\n",
    "    #LODO_pairs_index.shape\n",
    "    \n",
    "    ###\n",
    "    for nsample in nsamples:\n",
    "        for min_paired in min_paireds:\n",
    "            print('###', disease, project, ntree, nsample, min_paired)\n",
    "            \n",
    "            overlap_features = features.loc[features['overlap_features']==1, :].index\n",
    "            trees = train_step(train, overlap_features, train_pairs, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            for name, dataset in extend_datasets.items():\n",
    "                score = roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))\n",
    "                results.append(['Study2Study', disease, ntree, nsample, min_paired, 'overlap', project, name, score])\n",
    "            ### LODO\n",
    "            trees = train_step(LODO_data, overlap_features, LODO_pairs_index, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            score = roc_auc_score(data['Group'], predict_step(trees, data, overlap_features))\n",
    "            results.append(['LODO', disease, ntree, nsample, min_paired, 'overlap', 'Others', project, score])\n",
    "            \n",
    "            \n",
    "            overlap_features = features.loc[(features['overlap_features']==1)&(features['unmatched_diff_features']==1), :].index\n",
    "            trees = train_step(train, overlap_features, train_pairs, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            for name, dataset in extend_datasets.items():\n",
    "                score = roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))\n",
    "                results.append(['Study2Study', disease, ntree, nsample, min_paired, 'unmatched', project, name, score])\n",
    "                \n",
    "            ### LODO\n",
    "            trees = train_step(LODO_data, overlap_features, LODO_pairs_index, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            score = roc_auc_score(data['Group'], predict_step(trees, data, overlap_features))\n",
    "            results.append(['LODO', disease, ntree, nsample, min_paired, 'unmatched', 'Others', project, score])\n",
    "                \n",
    "            overlap_features = features.loc[(features['overlap_features']==1)&(features['matched_diff_features']==1), :].index\n",
    "            trees = train_step(train, overlap_features, train_pairs, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            for name, dataset in extend_datasets.items():\n",
    "                score = roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))\n",
    "                results.append(['Study2Study', disease, ntree, nsample, min_paired, 'matched', project, name, score])\n",
    "            \n",
    "            ### LODO\n",
    "            trees = train_step(LODO_data, overlap_features, LODO_pairs_index, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            score = roc_auc_score(data['Group'], predict_step(trees, data, overlap_features))\n",
    "            results.append(['LODO', disease, ntree, nsample, min_paired, 'matched', 'Others', project, score])\n",
    "    \n",
    "\n",
    "results = pd.DataFrame(results, columns=['Type', 'Disease', 'NTree', 'NSample', 'Min_paired_ratio', 'Feature', 'TrainingSet', 'TestSet', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffbaa424-3b02-4e70-bf78-3d21d45534a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('M2. Emsemble_'+disease+'.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75451595-1a7f-4381-907b-c1e1de7c229e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc2e663-b6f6-4914-abe7-d0423d1147e5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### CRC 99_2 101 3 0.0\n",
      "### CRC 99_2 101 3 0.1\n",
      "### CRC 99_2 101 3 0.2\n",
      "### CRC 99_2 101 3 0.3\n",
      "### CRC 99_2 101 3 0.4\n",
      "### CRC 99_2 101 3 0.5\n",
      "### CRC 99_2 101 3 0.6\n",
      "### CRC 99_2 101 3 0.7\n",
      "### CRC 99_2 101 3 0.8\n",
      "### CRC 99_2 101 3 0.9\n",
      "### CRC 99_2 101 3 1.0\n",
      "### CRC 99_2 101 5 0.0\n",
      "### CRC 99_2 101 5 0.1\n",
      "### CRC 99_2 101 5 0.2\n",
      "### CRC 99_2 101 5 0.3\n",
      "### CRC 99_2 101 5 0.4\n",
      "### CRC 99_2 101 5 0.5\n",
      "### CRC 99_2 101 5 0.6\n",
      "### CRC 99_2 101 5 0.7\n",
      "### CRC 99_2 101 5 0.8\n",
      "### CRC 99_2 101 5 0.9\n",
      "### CRC 99_2 101 5 1.0\n",
      "### CRC 99_2 101 7 0.0\n",
      "### CRC 99_2 101 7 0.1\n",
      "### CRC 99_2 101 7 0.2\n",
      "### CRC 99_2 101 7 0.3\n",
      "### CRC 99_2 101 7 0.4\n",
      "### CRC 99_2 101 7 0.5\n",
      "### CRC 99_2 101 7 0.6\n",
      "### CRC 99_2 101 7 0.7\n",
      "### CRC 99_2 101 7 0.8\n",
      "### CRC 99_2 101 7 0.9\n",
      "### CRC 99_2 101 7 1.0\n",
      "### CRC 99_2 101 9 0.0\n",
      "### CRC 99_2 101 9 0.1\n",
      "### CRC 99_2 101 9 0.2\n",
      "### CRC 99_2 101 9 0.3\n",
      "### CRC 99_2 101 9 0.4\n",
      "### CRC 99_2 101 9 0.5\n",
      "### CRC 99_2 101 9 0.6\n",
      "### CRC 99_2 101 9 0.7\n",
      "### CRC 99_2 101 9 0.8\n",
      "### CRC 99_2 101 9 0.9\n",
      "### CRC 99_2 101 9 1.0\n",
      "### CRC 99_2 101 11 0.0\n",
      "### CRC 99_2 101 11 0.1\n",
      "### CRC 99_2 101 11 0.2\n",
      "### CRC 99_2 101 11 0.3\n",
      "### CRC 99_2 101 11 0.4\n",
      "### CRC 99_2 101 11 0.5\n",
      "### CRC 99_2 101 11 0.6\n",
      "### CRC 99_2 101 11 0.7\n",
      "### CRC 99_2 101 11 0.8\n",
      "### CRC 99_2 101 11 0.9\n",
      "### CRC 99_2 101 11 1.0\n"
     ]
    }
   ],
   "source": [
    "projects = ['18_2', '26', '28_2', '81_2', '82', '83', '87', '91', '93_3', '97', '99_2']\n",
    "disease = 'CRC'\n",
    "ntree = 101\n",
    "nsamples = [3, 5, 7, 9, 11]\n",
    "min_paireds = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "results = []\n",
    "for project in projects:\n",
    "    ### data\n",
    "    data, pairs, train, valid, test, pairTrain, train_pairs, pairValid, valid_pairs, features = load_data(project, path='./dataset/')\n",
    "    extend_datasets = {}\n",
    "    LODO_data = pd.DataFrame()\n",
    "    LODO_pairs = pd.DataFrame()\n",
    "    for i in projects:\n",
    "        if i!=project:\n",
    "            extend_datasets[i], extend_pairs = load_data(i, path='./dataset/')[:2]\n",
    "            temp = extend_datasets[i].copy()\n",
    "            temp.index = i+'_'+temp.index\n",
    "            LODO_data = pd.concat([LODO_data, temp], axis=0, sort=False)\n",
    "            extend_pairs = i+'_'+extend_pairs\n",
    "            LODO_pairs = pd.concat([LODO_pairs, extend_pairs], axis=0, sort=False)\n",
    "    extend_datasets[project+'_train'] = train\n",
    "    extend_datasets[project+'_valid'] = valid\n",
    "    extend_datasets[project+'_test'] = test\n",
    "\n",
    "    #LODO_data.shape\n",
    "    LODO_pairs_index = []\n",
    "    samples = list(LODO_data.index)\n",
    "    for case, control in LODO_pairs.values:\n",
    "        LODO_pairs_index.append([samples.index(case), samples.index(control)])\n",
    "    LODO_pairs_index = pd.DataFrame(LODO_pairs_index, columns=['Case', 'Control'])\n",
    "    #LODO_pairs_index.shape\n",
    "    \n",
    "    ###\n",
    "    for nsample in nsamples:\n",
    "        for min_paired in min_paireds:\n",
    "            print('###', disease, project, ntree, nsample, min_paired)\n",
    "            \n",
    "            overlap_features = features.loc[features['overlap_features']==1, :].index\n",
    "            trees = train_step(train, overlap_features, train_pairs, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            for name, dataset in extend_datasets.items():\n",
    "                score = roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))\n",
    "                results.append(['Study2Study', disease, ntree, nsample, min_paired, 'overlap', project, name, score])\n",
    "            ### LODO\n",
    "            trees = train_step(LODO_data, overlap_features, LODO_pairs_index, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            score = roc_auc_score(data['Group'], predict_step(trees, data, overlap_features))\n",
    "            results.append(['LODO', disease, ntree, nsample, min_paired, 'overlap', 'Others', project, score])\n",
    "            \n",
    "            \n",
    "            overlap_features = features.loc[(features['overlap_features']==1)&(features['unmatched_diff_features']==1), :].index\n",
    "            trees = train_step(train, overlap_features, train_pairs, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            for name, dataset in extend_datasets.items():\n",
    "                score = roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))\n",
    "                results.append(['Study2Study', disease, ntree, nsample, min_paired, 'unmatched', project, name, score])\n",
    "                \n",
    "            ### LODO\n",
    "            trees = train_step(LODO_data, overlap_features, LODO_pairs_index, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            score = roc_auc_score(data['Group'], predict_step(trees, data, overlap_features))\n",
    "            results.append(['LODO', disease, ntree, nsample, min_paired, 'unmatched', 'Others', project, score])\n",
    "                \n",
    "            overlap_features = features.loc[(features['overlap_features']==1)&(features['matched_diff_features']==1), :].index\n",
    "            if len(overlap_features)==0:\n",
    "                continue\n",
    "            trees = train_step(train, overlap_features, train_pairs, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            for name, dataset in extend_datasets.items():\n",
    "                score = roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))\n",
    "                results.append(['Study2Study', disease, ntree, nsample, min_paired, 'matched', project, name, score])\n",
    "            \n",
    "            ### LODO\n",
    "            trees = train_step(LODO_data, overlap_features, LODO_pairs_index, ntree=ntree, nsample=nsample, min_paired=min_paired)\n",
    "            score = roc_auc_score(data['Group'], predict_step(trees, data, overlap_features))\n",
    "            results.append(['LODO', disease, ntree, nsample, min_paired, 'matched', 'Others', project, score])\n",
    "    \n",
    "\n",
    "results = pd.DataFrame(results, columns=['Type', 'Disease', 'NTree', 'NSample', 'Min_paired_ratio', 'Feature', 'TrainingSet', 'TestSet', 'AUC'])\n",
    "results.to_csv('M2. Emsemble_'+disease+'.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f6c4b94-c2eb-4319-9c1d-ea0bf04cf8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LODO_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdd889-134a-44f8-8d0c-5d3549e7fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c26f7-86e3-40d9-9db0-2814318cf96b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "overlap_features = features.loc[features['overlap_features']==1, :].index\n",
    "trees = train_step(train, overlap_features, train_pairs, ntree=301, nsample=7, min_paired=0.0)\n",
    "for name, dataset in extend_datasets.items():\n",
    "    name, roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c92ee4d-e59b-483b-88f0-9507f9041774",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "overlap_features = features.loc[features['overlap_features']==1, :].index\n",
    "trees = train_step(train, overlap_features, train_pairs, ntree=301, nsample=7, min_paired=0.2)\n",
    "for name, dataset in extend_datasets.items():\n",
    "    name, roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ca9bf-893f-4df8-b357-f1e051435749",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_features = features.loc[features['overlap_features']==1, :].index\n",
    "trees = train_step(train, overlap_features, train_pairs, ntree=301, nsample=7, min_paired=0.5)\n",
    "for name, dataset in extend_datasets.items():\n",
    "    name, roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257424d-4769-44d4-90ba-f2b28fc8158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_features = features.loc[(features['overlap_features']==1)&(features['matched_diff_features']==1), :].index\n",
    "trees = train_step(train, overlap_features, train_pairs, ntree=301, nsample=7, min_paired=0.5)\n",
    "for name, dataset in extend_datasets.items():\n",
    "    name, roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe24f5-a6d9-42a7-ad2e-158cd46396c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c36d08-c9ea-4bb8-9a56-17483fe2829b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddac432-4186-488d-9982-7c6893aea550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da0d29-8c80-49ae-a14f-8d9a50f04a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_features = features.loc[(features['overlap_features']==1)&(features['unmatched_diff_features']==1), :].index\n",
    "trees = train_step(train, overlap_features, train_pairs, ntree=101, nsample=7)\n",
    "for name, dataset in extend_datasets.items():\n",
    "    name, roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c463496d-167f-4ff1-ba98-5b98808bdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_features = features.loc[(features['overlap_features']==1)&(features['matched_diff_features']==1), :].index\n",
    "trees = train_step(train, overlap_features, train_pairs, ntree=101, nsample=7)\n",
    "for name, dataset in extend_datasets.items():\n",
    "    name, roc_auc_score(dataset['Group'], predict_step(trees, dataset, overlap_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40913ab-a07b-453d-b3c6-3c9556ca28a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
